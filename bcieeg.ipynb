{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Tgoh1wYyiRRDUyemYECNRAN30S-d1JGc",
      "authorship_tag": "ABX9TyO/BQvWhiHnO2IrUx/9Mf8W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snoopies/EEGTest/blob/main/bcieeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**model.py**"
      ],
      "metadata": {
        "id": "cCoqY8yp31eh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez0GDqI10HEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670ec5d4-c5db-4f12-98d6-42d682b108e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 22, 1001]             512\n",
            "       BatchNorm2d-2          [-1, 8, 22, 1001]              16\n",
            "            Conv2d-3          [-1, 16, 1, 1001]             352\n",
            "       BatchNorm2d-4          [-1, 16, 1, 1001]              32\n",
            "               ELU-5          [-1, 16, 1, 1001]               0\n",
            "         AvgPool2d-6           [-1, 16, 1, 250]               0\n",
            "           Dropout-7           [-1, 16, 1, 250]               0\n",
            "            Conv2d-8           [-1, 16, 1, 251]             256\n",
            "            Conv2d-9           [-1, 16, 1, 251]             256\n",
            "      BatchNorm2d-10           [-1, 16, 1, 251]              32\n",
            "              ELU-11           [-1, 16, 1, 251]               0\n",
            "        AvgPool2d-12            [-1, 16, 1, 31]               0\n",
            "          Dropout-13            [-1, 16, 1, 31]               0\n",
            "           Linear-14                    [-1, 4]           1,984\n",
            "          Softmax-15                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 3,440\n",
            "Trainable params: 3,440\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 3.25\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 3.34\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 导入必要的库\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "# 按照论文创建EEGNet\n",
        "class EEGNet(nn.Module):\n",
        "    def __init__(self, n_classes=4, channels=22, samples=1000,\n",
        "                 dropout_rate=0.5, kernel_length1=64, kernel_length2=16,\n",
        "                 f1=8, d=2, f2=16):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.f1 = f1\n",
        "        self.f2 = f2\n",
        "        self.d = d\n",
        "        self.samples = samples\n",
        "        self.n_classes = n_classes\n",
        "        self.channels = channels\n",
        "        self.kernel_length1 = kernel_length1\n",
        "        self.kernel_length2 = kernel_length2\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        block1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=self.f1,\n",
        "                kernel_size=(1, self.kernel_length1),\n",
        "                stride=1,\n",
        "                padding=(0, self.kernel_length1//2),\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=self.f1)\n",
        "        )\n",
        "\n",
        "        block2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.f1,\n",
        "                out_channels=self.f1*self.d,\n",
        "                kernel_size=(self.channels, 1),\n",
        "                groups=self.f1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=self.f1*self.d),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(\n",
        "                kernel_size=(1, 4),\n",
        "                stride=4\n",
        "            ),\n",
        "            nn.Dropout(p=self.dropout_rate)\n",
        "        )\n",
        "\n",
        "        block3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.f2,\n",
        "                out_channels=self.f2,\n",
        "                kernel_size=(1, self.kernel_length2),\n",
        "                stride=1,\n",
        "                padding=(0, self.kernel_length2//2),\n",
        "                groups=self.f1*self.d,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.f1*self.d,\n",
        "                out_channels=self.f2,\n",
        "                kernel_size=(1, 1),\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=self.f2),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(\n",
        "                kernel_size=(1, 8),\n",
        "                stride=8\n",
        "            ),\n",
        "            nn.Dropout(p=self.dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.EEGNetLayer = nn.Sequential(block1, block2, block3)\n",
        "\n",
        "        self.ClassifierBlock = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                in_features=self.f2*round(round(self.samples//4)//8),\n",
        "                out_features=self.n_classes,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) != 4:\n",
        "            x = torch.unsqueeze(x, dim=1)\n",
        "        x = self.EEGNetLayer(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.ClassifierBlock(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# 模型结构可视化\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = EEGNet().to(device)\n",
        "    print(summary(model, input_size=(1, 22, 1000)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model_train.py**"
      ],
      "metadata": {
        "id": "FEh-At_B4JEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import mne\n",
        "import scipy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import copy\n",
        "import time\n",
        "#from model import EEGNet\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 1、创建必要的本地目录，用于保存数据\n",
        "if not os.path.exists('2a_train_pre'):\n",
        "    os.makedirs('2a_train_pre')\n",
        "\n",
        "# 2、原始数据读取和通道重命名\n",
        "data_path = ['A0'+str(i)+'T' for i in range(1, 10)]\n",
        "raw = [mne.io.read_raw_gdf(input_fname='./'+path+'.gdf',\n",
        "                           stim_channel=\"auto\",\n",
        "                           preload=True,\n",
        "                           verbose=\"error\") for path in data_path]\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    raw[i].rename_channels({'EEG-Fz': 'Fz', 'EEG-0': 'FC3', 'EEG-1': 'FC1', 'EEG-2': 'FCz', 'EEG-3': 'FC2',\n",
        "                            'EEG-4': 'FC4', 'EEG-5': 'C5', 'EEG-C3': 'C3', 'EEG-6': 'C1', 'EEG-Cz': 'Cz',\n",
        "                            'EEG-7': 'C2', 'EEG-C4': 'C4', 'EEG-8': 'C6', 'EEG-9': 'CP3', 'EEG-10': 'CP1',\n",
        "                            'EEG-11': 'CPz', 'EEG-12': 'CP2', 'EEG-13': 'CP4', 'EEG-14': 'P1', 'EEG-15': 'Pz',\n",
        "                            'EEG-16': 'P2', 'EEG-Pz': 'POz'})\n",
        "\n",
        "# 3、提取MI时间，完成坏值清洗，并封装\n",
        "events = []\n",
        "event_ids = []\n",
        "for i in range(len(raw)):\n",
        "    event_to_id = dict({'769': 7, '770': 8, '771': 9, '772': 10})\n",
        "    if i == 3:\n",
        "        event_to_id = dict({'769': 5, '770': 6, '771': 7, '772': 8})\n",
        "        event, _ = mne.events_from_annotations(raw[i], verbose=False)\n",
        "        events.append(event)\n",
        "        ids = np.unique(events[i][:, 2])\n",
        "        event_id = {k: v for k, v in event_to_id.items() if v in ids}\n",
        "        event_ids.append(event_id)\n",
        "        raw[i].load_data()\n",
        "        data = raw[i].get_data()\n",
        "    else:\n",
        "        event, _ = mne.events_from_annotations(raw[i], verbose=False)\n",
        "        events.append(event)\n",
        "        ids = np.unique(events[i][:, 2])\n",
        "        event_id = {k: v for k, v in event_to_id.items() if v in ids}\n",
        "        event_ids.append(event_id)\n",
        "        raw[i].load_data()\n",
        "        data = raw[i].get_data()\n",
        "    for i_chan in range(data.shape[0]):\n",
        "        chan = data[i_chan]\n",
        "        data[i_chan] = np.where(chan == np.min(chan), np.nan, chan)\n",
        "        mask = np.isnan(data[i_chan])\n",
        "        chan_mean = np.nanmean(data[i_chan])\n",
        "        data[i_chan, mask] = chan_mean\n",
        "    raw[i] = mne.io.RawArray(data, raw[i].info, verbose=\"error\")\n",
        "\n",
        "# 4、切段、去EOG、做标准化，封存数据为npz\n",
        "tmin, tmax = 0, 4\n",
        "for i in range(len(raw)):\n",
        "    epochs = mne.Epochs(raw[i], events[i], event_ids[i], tmin, tmax, proj=False, baseline=None, preload=True)\n",
        "\n",
        "    exclude = [\"EOG-left\", \"EOG-central\", \"EOG-right\"]\n",
        "    epochs.drop_channels(exclude)\n",
        "\n",
        "    print('./'+data_path[i]+'.mat')\n",
        "    labels_file = scipy.io.loadmat('./'+data_path[i]+'.mat')\n",
        "    labels = labels_file['classlabel'].reshape(288)\n",
        "    epochs_data = epochs.get_data(copy=True)[:, :, :-1]\n",
        "\n",
        "    n_samples, n_channels, n_timepoints = epochs_data.shape\n",
        "    epochs_data_flat = epochs_data.reshape(n_samples, -1)\n",
        "\n",
        "    scaler = StandardScaler().fit(epochs_data_flat)\n",
        "    data_scaled = scaler.transform(epochs_data_flat)\n",
        "\n",
        "    data_scaled = data_scaled.reshape(n_samples, n_channels, n_timepoints)\n",
        "\n",
        "    np.savez('2a_train_pre/'+data_path[i]+'.npz', data=data_scaled, label=labels)\n",
        "\n",
        "\n",
        "# 5、创建训练集和验证集数据加载器\n",
        "def create_simple_dataloaders():\n",
        "    # 加载数据\n",
        "    x_train, y_train = [], []\n",
        "    for i in range(1, 10):\n",
        "        train_data = np.load(f'2a_train_pre/A0{i}T.npz')\n",
        "        x_train.append(train_data['data'])\n",
        "        y_train.append(train_data['label'])\n",
        "\n",
        "    # 合并数据\n",
        "    x_train = np.concatenate(x_train)\n",
        "    y_train = np.concatenate(y_train)\n",
        "\n",
        "    # 转换为PyTorch张量\n",
        "    x_train = torch.FloatTensor(x_train).unsqueeze(1)\n",
        "    y_train = torch.LongTensor(y_train - 1)\n",
        "\n",
        "    # 创建完整数据集\n",
        "    full_dataset = TensorDataset(x_train, y_train)\n",
        "\n",
        "    # 计算训练集和验证集大小\n",
        "    dataset_size = len(full_dataset)\n",
        "    val_size = int(dataset_size * 0.2)\n",
        "    train_size = dataset_size - val_size\n",
        "\n",
        "    # 划分训练集和验证集\n",
        "    train_data, val_data = random_split(\n",
        "        full_dataset,\n",
        "        [train_size, val_size]\n",
        "    )\n",
        "\n",
        "    # 创建DataLoader\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "# 6、训练模型\n",
        "def train_model_process(model, train_loader, val_loader, num_epochs):\n",
        "    # 设定训练所用到的设备，有GPU用GPU没有GPU用CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # 使用Adam优化器，学习率为0.001\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    # 损失函数为交叉熵函数\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # 将模型放入到训练设备中\n",
        "    model = model.to(device)\n",
        "    # 复制当前模型的参数\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # 初始化参数\n",
        "    best_acc = 0.0\n",
        "    train_loss_all = []\n",
        "    val_loss_all = []\n",
        "    train_acc_all = []\n",
        "    val_acc_all = []\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
        "        print(\"-\"*10)\n",
        "\n",
        "        # 初始化参数\n",
        "        train_loss = 0.0\n",
        "        train_corrects = 0\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        train_num = 0\n",
        "        val_num = 0\n",
        "\n",
        "        # 对每一个batch训练和计算\n",
        "        for step, (b_x, b_y) in enumerate(train_loader):\n",
        "            # 将特征放入到训练设备中\n",
        "            b_x = b_x.to(device)\n",
        "            # 将标签放入到训练设备中\n",
        "            b_y = b_y.to(device)\n",
        "            # 设置模型为训练模式\n",
        "            model.train()\n",
        "\n",
        "            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n",
        "            output = model(b_x)\n",
        "            # 查找每一行中最大值对应的行标\n",
        "            pre_lab = torch.argmax(output, dim=1)\n",
        "            # 计算每一个batch的损失函数\n",
        "            loss = criterion(output, b_y)\n",
        "\n",
        "            # 将梯度初始化为0\n",
        "            optimizer.zero_grad()\n",
        "            # 反向传播计算\n",
        "            loss.backward()\n",
        "            # 根据网络反向传播的梯度信息来更新网络的参数，以起到降低loss函数计算值的作用\n",
        "            optimizer.step()\n",
        "            # 对损失函数进行累加\n",
        "            train_loss += loss.item() * b_x.size(0)\n",
        "            # 如果预测正确，则准确度train_corrects加1\n",
        "            train_corrects += torch.sum(pre_lab == b_y.data)\n",
        "            # 当前用于训练的样本数量\n",
        "            train_num += b_x.size(0)\n",
        "\n",
        "        for step, (b_x, b_y) in enumerate(val_loader):\n",
        "            # 将特征放入到验证设备中\n",
        "            b_x = b_x.to(device)\n",
        "            # 将标签放入到验证设备中\n",
        "            b_y = b_y.to(device)\n",
        "            # 设置模型为评估模式\n",
        "            model.eval()\n",
        "            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n",
        "            output = model(b_x)\n",
        "            # 查找每一行中最大值对应的行标\n",
        "            pre_lab = torch.argmax(output, dim=1)\n",
        "            # 计算每一个batch的损失函数\n",
        "            loss = criterion(output, b_y)\n",
        "\n",
        "            # 对损失函数进行累加\n",
        "            val_loss += loss.item() * b_x.size(0)\n",
        "            # 如果预测正确，则准确度train_corrects加1\n",
        "            val_corrects += torch.sum(pre_lab == b_y.data)\n",
        "            # 当前用于验证的样本数量\n",
        "            val_num += b_x.size(0)\n",
        "\n",
        "        # 计算并保存每一次迭代的loss值和准确率\n",
        "        # 计算并保存训练集的loss值\n",
        "        train_loss_all.append(train_loss / train_num)\n",
        "        # 计算并保存训练集的准确率\n",
        "        train_acc_all.append(train_corrects.double().item() / train_num)\n",
        "\n",
        "        # 计算并保存验证集的loss值\n",
        "        val_loss_all.append(val_loss / val_num)\n",
        "        # 计算并保存验证集的准确率\n",
        "        val_acc_all.append(val_corrects.double().item() / val_num)\n",
        "\n",
        "        print(\"{} train loss:{:.4f} train acc: {:.4f}\".format(epoch, train_loss_all[-1], train_acc_all[-1]))\n",
        "        print(\"{} val loss:{:.4f} val acc: {:.4f}\".format(epoch, val_loss_all[-1], val_acc_all[-1]))\n",
        "\n",
        "        if val_acc_all[-1] > best_acc:\n",
        "            # 保存当前最高准确度\n",
        "            best_acc = val_acc_all[-1]\n",
        "            # 保存当前最高准确度的模型参数\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # 计算训练和验证的耗时\n",
        "        time_use = time.time() - since\n",
        "        print(\"训练和验证耗费的时间{:.0f}m{:.0f}s\".format(time_use//60, time_use % 60))\n",
        "\n",
        "    # 选择最优参数，保存最优参数的模型\n",
        "    torch.save(best_model_wts, \"best_model.pth\")\n",
        "\n",
        "    train_process = pd.DataFrame(data={\"epoch\": range(num_epochs),\n",
        "\"train_loss_all\": train_loss_all,\n",
        "\"val_loss_all\": val_loss_all,\n",
        "\"train_acc_all\": train_acc_all,\n",
        "\"val_acc_all\": val_acc_all})\n",
        "\n",
        "    return train_process\n",
        "\n",
        "\n",
        "# 7、可视化训练集和验证集的损失函数和准确率\n",
        "def matplot_acc_loss(train_process):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_process['epoch'], train_process.train_loss_all, \"ro-\", label=\"Train loss\")\n",
        "    plt.plot(train_process['epoch'], train_process.val_loss_all, \"bs-\", label=\"Val loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_process['epoch'], train_process.train_acc_all, \"ro-\", label=\"Train acc\")\n",
        "    plt.plot(train_process['epoch'], train_process.val_acc_all, \"bs-\", label=\"Val acc\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"acc\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 8、模型开始训练\n",
        "if __name__ == '__main__':\n",
        "    model = EEGNet()\n",
        "    train_loader, val_loader = create_simple_dataloaders()\n",
        "    train_process = train_model_process(model, train_loader, val_loader, num_epochs=500)\n",
        "    matplot_acc_loss(train_process)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aN-b-UvU3Y7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52dfb988-a848-4ad3-c2b5-43780146f2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "Using data from preloaded Raw for 288 events and 1001 original time points ...\n",
            "0 bad epochs dropped\n",
            "./A01T.mat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "Error -3 while decompressing data: invalid block type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-115397486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mlabels_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classlabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mepochs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/io/matlab/_mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/io/matlab/_mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    289\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         '''\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_cells\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_real_complex\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_element\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_streams.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream.read_string\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_streams.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream.read_into\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mscipy/io/matlab/_streams.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream._fill_buffer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: Error -3 while decompressing data: invalid block type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model_test.py**"
      ],
      "metadata": {
        "id": "U02guqzH4SWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import mne\n",
        "import scipy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from model import EEGNet\n",
        "import os\n",
        "\n",
        "\n",
        "# 1、创建必要的本地目录，用于保存数据\n",
        "if not os.path.exists('2a_test_pre'):\n",
        "    os.makedirs('2a_test_pre')\n",
        "\n",
        "# 2、原始数据读取和通道重命名\n",
        "data_path = ['A0'+str(i)+'E' for i in range(1, 10)]\n",
        "raw = [mne.io.read_raw_gdf(input_fname='./2a/'+path+'.gdf',\n",
        "                           stim_channel=\"auto\",\n",
        "                           preload=True,\n",
        "                           verbose='error') for path in data_path]\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    raw[i].rename_channels({'EEG-Fz': 'Fz', 'EEG-0': 'FC3', 'EEG-1': 'FC1', 'EEG-2': 'FCz', 'EEG-3': 'FC2',\n",
        "                            'EEG-4': 'FC4', 'EEG-5': 'C5', 'EEG-C3': 'C3', 'EEG-6': 'C1', 'EEG-Cz': 'Cz',\n",
        "                            'EEG-7': 'C2', 'EEG-C4': 'C4', 'EEG-8': 'C6', 'EEG-9': 'CP3', 'EEG-10': 'CP1',\n",
        "                            'EEG-11': 'CPz', 'EEG-12': 'CP2', 'EEG-13': 'CP4', 'EEG-14': 'P1', 'EEG-15': 'Pz',\n",
        "                            'EEG-16': 'P2', 'EEG-Pz': 'POz'})\n",
        "\n",
        "# 3、提取MI时间，完成坏值清洗，并封装\n",
        "event_to_id = dict({'783': 7})\n",
        "events = []\n",
        "event_ids = []\n",
        "for i in range(len(raw)):\n",
        "    event, _ = mne.events_from_annotations(raw[i])\n",
        "    events.append(event)\n",
        "    ids = np.unique(events[i][:, 2])\n",
        "    event_id = {k: v for k, v in event_to_id.items() if v in ids}\n",
        "    event_ids.append(event_id)\n",
        "\n",
        "    raw[i].load_data()\n",
        "    data = raw[i].get_data()\n",
        "    for i_chan in range(data.shape[0]):\n",
        "        chan = data[i_chan]\n",
        "        data[i_chan] = np.where(chan == np.min(chan), np.nan, chan)\n",
        "        mask = np.isnan(data[i_chan])\n",
        "        chan_mean = np.nanmean(data[i_chan])\n",
        "        data[i_chan, mask] = chan_mean\n",
        "    raw[i] = mne.io.RawArray(data, raw[i].info, verbose=\"error\")\n",
        "\n",
        "# 4、切段、去EOG、做标准化，封存数据为npz\n",
        "tmin, tmax = 0, 4\n",
        "for i in range(len(raw)):\n",
        "    epochs = mne.Epochs(raw[i], events[i], event_ids[i], tmin, tmax, proj=False, baseline=None, preload=True)\n",
        "    exclude = [\"EOG-left\", \"EOG-central\", \"EOG-right\"]\n",
        "    epochs.drop_channels(exclude)\n",
        "\n",
        "    labels_file = scipy.io.loadmat('2a_labels/'+data_path[i]+'.mat')\n",
        "    labels = labels_file['classlabel'].reshape(288)\n",
        "    epochs_data = epochs.get_data(copy=True)[:, :, :-1]\n",
        "\n",
        "    n_samples, n_channels, n_timepoints = epochs_data.shape\n",
        "    epochs_data_flat = epochs_data.reshape(n_samples, -1)\n",
        "\n",
        "    scaler = StandardScaler().fit(epochs_data_flat)\n",
        "    data_scaled = scaler.transform(epochs_data_flat)\n",
        "\n",
        "    data_scaled = data_scaled.reshape(n_samples, n_channels, n_timepoints)\n",
        "\n",
        "    np.savez('2a_test_pre/'+data_path[i]+'.npz', data=data_scaled, label=labels)\n",
        "\n",
        "\n",
        "# 5、创建测试集数据加载器\n",
        "def create_simple_dataloaders():\n",
        "    # 加载数据\n",
        "    x_test, y_test = [], []\n",
        "    for i in range(1, 10):\n",
        "        test_data = np.load(f'2a_test_pre/A0{i}E.npz')\n",
        "        x_test.append(test_data['data'])\n",
        "        y_test.append(test_data['label'])\n",
        "\n",
        "    # 合并数据\n",
        "    x_test = np.concatenate(x_test)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    # 转换为PyTorch张量\n",
        "    x_test = torch.FloatTensor(x_test).unsqueeze(1)\n",
        "    y_test = torch.LongTensor(y_test - 1)\n",
        "\n",
        "    # 创建DataLoader\n",
        "    test_loader = DataLoader(\n",
        "        TensorDataset(x_test, y_test),\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return test_loader\n",
        "\n",
        "\n",
        "# 6、模型测试\n",
        "def test_model_process(model, test_loader):\n",
        "    # 设定测试所用到的设备，有GPU用GPU没有GPU用CPU\n",
        "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "    # 讲模型放入到训练设备中\n",
        "    model = model.to(device)\n",
        "    # 初始化参数\n",
        "    test_corrects = 0.0\n",
        "    test_num = 0\n",
        "    # 只进行前向传播计算，不计算梯度，从而节省内存，加快运行速度\n",
        "    with torch.no_grad():\n",
        "        for test_data_x, test_data_y in test_loader:\n",
        "            # 将特征放入到测试设备中\n",
        "            test_data_x = test_data_x.to(device)\n",
        "            # 将标签放入到测试设备中\n",
        "            test_data_y = test_data_y.to(device)\n",
        "            # 设置模型为评估模式\n",
        "            model.eval()\n",
        "            # 前向传播过程，输入为测试数据集，输出为对每个样本的预测值\n",
        "            output = model(test_data_x)\n",
        "            # 查找每一行中最大值对应的行标\n",
        "            pre_lab = torch.argmax(output, dim=1)\n",
        "            # 如果预测正确，则准确度test_corrects加1\n",
        "            test_corrects += torch.sum(pre_lab == test_data_y.data)\n",
        "            # 将所有的测试样本进行累加\n",
        "            test_num += test_data_x.size(0)\n",
        "\n",
        "    # 计算测试准确率\n",
        "    test_acc = test_corrects.double().item() / test_num\n",
        "    print(\"测试的准确率为：\", test_acc)\n",
        "\n",
        "\n",
        "# 7、模型开始测试\n",
        "if __name__ == \"__main__\":\n",
        "    model = EEGNet()\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    test_loader = create_simple_dataloaders()\n",
        "    test_model_process(model, test_loader)\n"
      ],
      "metadata": {
        "id": "OqfBuPsq3p2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "836962e2-5c96-4b71-9577-f5123d7ac6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-665368722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEEGNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***获取数据并解压***"
      ],
      "metadata": {
        "id": "Y_5mZ-dPoeWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09E.mat\n",
        "!unzip -q BCICIV_2a_gdf.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo7_FvGtnYgE",
        "outputId": "c4b6c424-2077-46cb-fb41-f4750d480012"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-05 07:10:42--  https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n",
            "Resolving www.bbci.de (www.bbci.de)... 141.23.71.83\n",
            "Connecting to www.bbci.de (www.bbci.de)|141.23.71.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439968864 (420M) [application/zip]\n",
            "Saving to: ‘BCICIV_2a_gdf.zip’\n",
            "\n",
            "BCICIV_2a_gdf.zip   100%[===================>] 419.59M  25.9MB/s    in 18s     \n",
            "\n",
            "2025-11-05 07:11:00 (23.4 MB/s) - ‘BCICIV_2a_gdf.zip’ saved [439968864/439968864]\n",
            "\n",
            "--2025-11-05 07:11:00--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A01T.mat [following]\n",
            "--2025-11-05 07:11:01--  https://lampx.tugraz.at/~bci/database/001-2014/A01T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42806453 (41M)\n",
            "Saving to: ‘A01T.mat’\n",
            "\n",
            "A01T.mat            100%[===================>]  40.82M  16.4MB/s    in 2.5s    \n",
            "\n",
            "2025-11-05 07:11:05 (16.4 MB/s) - ‘A01T.mat’ saved [42806453/42806453]\n",
            "\n",
            "--2025-11-05 07:11:05--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A02T.mat [following]\n",
            "--2025-11-05 07:11:05--  https://lampx.tugraz.at/~bci/database/001-2014/A02T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43068077 (41M)\n",
            "Saving to: ‘A02T.mat’\n",
            "\n",
            "A02T.mat            100%[===================>]  41.07M  16.5MB/s    in 2.5s    \n",
            "\n",
            "2025-11-05 07:11:08 (16.5 MB/s) - ‘A02T.mat’ saved [43068077/43068077]\n",
            "\n",
            "--2025-11-05 07:11:08--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A03T.mat [following]\n",
            "--2025-11-05 07:11:09--  https://lampx.tugraz.at/~bci/database/001-2014/A03T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44057065 (42M)\n",
            "Saving to: ‘A03T.mat’\n",
            "\n",
            "A03T.mat            100%[===================>]  42.02M  17.5MB/s    in 2.4s    \n",
            "\n",
            "2025-11-05 07:11:12 (17.5 MB/s) - ‘A03T.mat’ saved [44057065/44057065]\n",
            "\n",
            "--2025-11-05 07:11:12--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A04T.mat [following]\n",
            "--2025-11-05 07:11:13--  https://lampx.tugraz.at/~bci/database/001-2014/A04T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37150377 (35M)\n",
            "Saving to: ‘A04T.mat’\n",
            "\n",
            "A04T.mat            100%[===================>]  35.43M  10.3MB/s    in 3.4s    \n",
            "\n",
            "2025-11-05 07:11:17 (10.3 MB/s) - ‘A04T.mat’ saved [37150377/37150377]\n",
            "\n",
            "--2025-11-05 07:11:17--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A05T.mat [following]\n",
            "--2025-11-05 07:11:17--  https://lampx.tugraz.at/~bci/database/001-2014/A05T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42452392 (40M)\n",
            "Saving to: ‘A05T.mat’\n",
            "\n",
            "A05T.mat            100%[===================>]  40.49M  10.8MB/s    in 3.8s    \n",
            "\n",
            "2025-11-05 07:11:22 (10.8 MB/s) - ‘A05T.mat’ saved [42452392/42452392]\n",
            "\n",
            "--2025-11-05 07:11:22--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A06T.mat [following]\n",
            "--2025-11-05 07:11:22--  https://lampx.tugraz.at/~bci/database/001-2014/A06T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44581256 (43M)\n",
            "Saving to: ‘A06T.mat’\n",
            "\n",
            "A06T.mat            100%[===================>]  42.52M  10.9MB/s    in 3.9s    \n",
            "\n",
            "2025-11-05 07:11:27 (10.9 MB/s) - ‘A06T.mat’ saved [44581256/44581256]\n",
            "\n",
            "--2025-11-05 07:11:27--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A07T.mat [following]\n",
            "--2025-11-05 07:11:27--  https://lampx.tugraz.at/~bci/database/001-2014/A07T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42809746 (41M)\n",
            "Saving to: ‘A07T.mat’\n",
            "\n",
            "A07T.mat            100%[===================>]  40.83M  10.6MB/s    in 3.9s    \n",
            "\n",
            "2025-11-05 07:11:32 (10.6 MB/s) - ‘A07T.mat’ saved [42809746/42809746]\n",
            "\n",
            "--2025-11-05 07:11:32--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A08T.mat [following]\n",
            "--2025-11-05 07:11:32--  https://lampx.tugraz.at/~bci/database/001-2014/A08T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45032065 (43M)\n",
            "Saving to: ‘A08T.mat’\n",
            "\n",
            "A08T.mat            100%[===================>]  42.95M  11.4MB/s    in 3.8s    \n",
            "\n",
            "2025-11-05 07:11:37 (11.4 MB/s) - ‘A08T.mat’ saved [45032065/45032065]\n",
            "\n",
            "--2025-11-05 07:11:37--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A09T.mat [following]\n",
            "--2025-11-05 07:11:38--  https://lampx.tugraz.at/~bci/database/001-2014/A09T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44785478 (43M)\n",
            "Saving to: ‘A09T.mat’\n",
            "\n",
            "A09T.mat            100%[===================>]  42.71M  10.7MB/s    in 4.0s    \n",
            "\n",
            "2025-11-05 07:11:42 (10.7 MB/s) - ‘A09T.mat’ saved [44785478/44785478]\n",
            "\n",
            "--2025-11-05 07:11:42--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A01E.mat [following]\n",
            "--2025-11-05 07:11:43--  https://lampx.tugraz.at/~bci/database/001-2014/A01E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43772146 (42M)\n",
            "Saving to: ‘A01E.mat’\n",
            "\n",
            "A01E.mat            100%[===================>]  41.74M  11.0MB/s    in 3.8s    \n",
            "\n",
            "2025-11-05 07:11:47 (11.0 MB/s) - ‘A01E.mat’ saved [43772146/43772146]\n",
            "\n",
            "--2025-11-05 07:11:47--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A02E.mat [following]\n",
            "--2025-11-05 07:11:48--  https://lampx.tugraz.at/~bci/database/001-2014/A02E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44218409 (42M)\n",
            "Saving to: ‘A02E.mat’\n",
            "\n",
            "A02E.mat            100%[===================>]  42.17M  11.3MB/s    in 3.7s    \n",
            "\n",
            "2025-11-05 07:11:52 (11.3 MB/s) - ‘A02E.mat’ saved [44218409/44218409]\n",
            "\n",
            "--2025-11-05 07:11:52--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A03E.mat [following]\n",
            "--2025-11-05 07:11:53--  https://lampx.tugraz.at/~bci/database/001-2014/A03E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42316292 (40M)\n",
            "Saving to: ‘A03E.mat’\n",
            "\n",
            "A03E.mat            100%[===================>]  40.36M  10.8MB/s    in 3.7s    \n",
            "\n",
            "2025-11-05 07:11:57 (10.8 MB/s) - ‘A03E.mat’ saved [42316292/42316292]\n",
            "\n",
            "--2025-11-05 07:11:57--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A04E.mat [following]\n",
            "--2025-11-05 07:11:58--  https://lampx.tugraz.at/~bci/database/001-2014/A04E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41730824 (40M)\n",
            "Saving to: ‘A04E.mat’\n",
            "\n",
            "A04E.mat            100%[===================>]  39.80M  10.9MB/s    in 3.6s    \n",
            "\n",
            "2025-11-05 07:12:02 (10.9 MB/s) - ‘A04E.mat’ saved [41730824/41730824]\n",
            "\n",
            "--2025-11-05 07:12:02--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A05E.mat [following]\n",
            "--2025-11-05 07:12:03--  https://lampx.tugraz.at/~bci/database/001-2014/A05E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44392496 (42M)\n",
            "Saving to: ‘A05E.mat’\n",
            "\n",
            "A05E.mat            100%[===================>]  42.34M  11.2MB/s    in 3.8s    \n",
            "\n",
            "2025-11-05 07:12:07 (11.2 MB/s) - ‘A05E.mat’ saved [44392496/44392496]\n",
            "\n",
            "--2025-11-05 07:12:07--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A06E.mat [following]\n",
            "--2025-11-05 07:12:08--  https://lampx.tugraz.at/~bci/database/001-2014/A06E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43395510 (41M)\n",
            "Saving to: ‘A06E.mat’\n",
            "\n",
            "A06E.mat            100%[===================>]  41.38M  11.1MB/s    in 3.7s    \n",
            "\n",
            "2025-11-05 07:12:12 (11.1 MB/s) - ‘A06E.mat’ saved [43395510/43395510]\n",
            "\n",
            "--2025-11-05 07:12:12--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A07E.mat [following]\n",
            "--2025-11-05 07:12:13--  https://lampx.tugraz.at/~bci/database/001-2014/A07E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42242294 (40M)\n",
            "Saving to: ‘A07E.mat’\n",
            "\n",
            "A07E.mat            100%[===================>]  40.29M  11.2MB/s    in 3.6s    \n",
            "\n",
            "2025-11-05 07:12:17 (11.2 MB/s) - ‘A07E.mat’ saved [42242294/42242294]\n",
            "\n",
            "--2025-11-05 07:12:17--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A08E.mat [following]\n",
            "--2025-11-05 07:12:18--  https://lampx.tugraz.at/~bci/database/001-2014/A08E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46282127 (44M)\n",
            "Saving to: ‘A08E.mat’\n",
            "\n",
            "A08E.mat            100%[===================>]  44.14M  10.7MB/s    in 4.1s    \n",
            "\n",
            "2025-11-05 07:12:22 (10.7 MB/s) - ‘A08E.mat’ saved [46282127/46282127]\n",
            "\n",
            "--2025-11-05 07:12:22--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A09E.mat [following]\n",
            "--2025-11-05 07:12:23--  https://lampx.tugraz.at/~bci/database/001-2014/A09E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44780912 (43M)\n",
            "Saving to: ‘A09E.mat’\n",
            "\n",
            "A09E.mat            100%[===================>]  42.71M  11.0MB/s    in 3.9s    \n",
            "\n",
            "2025-11-05 07:12:28 (11.0 MB/s) - ‘A09E.mat’ saved [44780912/44780912]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}